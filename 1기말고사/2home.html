<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" type="text/css" href="style_layout.css">
    <link rel="stylesheet" type="text/css" href="style_color.css">
    <meta author="소프트웨어학과 202121028 김동우">
    <meta charset="utf-8"/>
</head>

<body>
<div class="background">
    <div class="windowcon"><!--사진 5장 무한 슬라이드-->
        <div class="container">
            <img src="images/01.png" width="1280px" height="720">
            <img src="images/02.png" width="1280px" height="720">
            <img src="images/03.png" width="1280px" height="720">
            <img src="images/04.png" width="1280px" height="720">
            <img src="images/05.png" width="1280px" height="720">
            <img src="images/01.png" width="1280px" height="720"><!--처음 사진을 끝에 꼭 넣어줘야함-->       
        </div>
    </div>

    <div id="left_box"><!--왼쪽 공지사항 알림판-->
        <p id="box_title">Announcement📢</p>
        <ol id="box_list">
            <div id="list1">
            
            </div>
        </ol>
    </div>

    <div id="right_box"><!--오른쪽 인기글 알림판-->
        <p id="box_title">Hot🔥</p>
        <ol id="box_list">
            <div id="list2">
            
            </div>
        </ol>
    </div>
</div>
</body>

    <script>
    const windowcon = document.querySelector('.windowcon'),
        container = document.querySelector('.container'),
            slides = document.querySelectorAll('img'),
            slidecounter = slides.length;
    let currentIndex = 0;
    
    for(i=0; i < slidecounter; i++){
        slides[i].style.left = `${i*100}%`;
    
    }
    
    function calcul(){
        for(i=0; i<slidecounter; i++){
            if(windowcon.offsetHeight < slides[i].offsetHeight){
                windowcon.style.height = slides[i].offsetHeight +"px";
                windowcon.style.width = slides[i].offsetWidth +"px";
            }
        }
    }
    
    calcul();
    var lele = 0;
    var i = 0;
    
    function moveevent(){
        setInterval(function(){
            lele += 100;
            container.style.transition ='.3s'
            container.style.left ="-" + lele +"%";
            i++;
            
            if(i === slidecounter-1){
                setTimeout(function(){
                    container.style.transition ='0s'
                    lele = 0;
                    container.style.left ="-" + lele +"%";
                },201)
                i = 0;
            }
        }, 5000)//5000ms마다 사진을 넘김
    }

    moveevent();

    function config(){
        if(!window.localStorage.getItem("board")){//localstorage에 board가 없어야 작동
            console.log("board set!");
            window.localStorage.setItem("board",JSON.stringify(board1));//localstorage에 배열을 저장하는 방법
            //첫 실행시 localstorage에 board를 배열 형태로 저장함.
            //여기에서 forum글 뜨는 것과 forum의 글 작성, 수정, 삭제, 좋아요 기능이 연동되게 하기 위함
        }
    }

    var board1 = [];
    board1[0] = ["안녕하세요","Datawiki에 오신 것을 환영합니다.","2022.05.01","10"];
    board1[1] = ["관리자소개","Datawiki의 관리자를 소개 합니다.","2022.05.05","5"];
    board1[2] = ["최신 뉴스","Datawiki는 상명대 천안캠퍼스에서 주관하는 데이터 공유 사이트 입니다.","2022.05.06","22"];
    board1[3] = ["공지사항","Datawiki가 새롭게 단장됩니다. 더욱 개선된 사이트를 기대해 주세요.","2022.05.08","100"];
    board1[4] = ["추가 공지 사항","Datawiki를 새롭게 개선하기 위한 메니저를 공모합니다. ","2022.05.10","1"];
    board1[5] = ["2022년 데이터위키 공모전","2022년 데이터 위키는 이미지 인식 주제로 진행합니다.","2022.05.12","44"];
    board1[6] = ["공모전 종료 안내","2022년 데이터 위키 공모전이 성공리에 마감 되었습니다. ","2022.05.14","50"];
    board1[7] = ["2023년 데이터 위키 공모전","2023년 데이터 위키 공모전을 소개 합니다.","2022.05.16","49"];
    board1[8] = ["학기 종료 안내","22년 1학기 종료까지 이제 6주 남았습니다. ","2022.05.18","17"];
    board1[9] = ["튜토리얼 공지","tensorflow와 keras의 라이브러리를 이용하여 같이 공부해 봅시다.","2022.05.19","84"];
    board1[10] = ["신규 데이터 요청","새로운 데이터가 필요하신 분은 언제든 요청 바랍니다.","2022.05.21","3"];
    board1[11] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[12] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[13] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[14] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[15] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[16] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[17] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[18] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[19] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[20] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[21] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[22] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[23] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[24] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[25] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[26] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[27] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[28] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[29] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[30] = ["페이지 넘김 기능 테스트를 위해 생성한 글","테스트","1999.12.31","0"];
    board1[31] = ["< 버튼을 누르면 다음 페이지로 넘어감","테스트","2000.01.01","0"];
    board1[32] = ["> 버튼을 누르면 이전 페이지로 넘어감","테스트","2000.01.01","0"];
    board1[33] = ["관리자 비밀번호는 1234 입니다.","아시겠죵?","2001.01.01","0"]

    var dataset = [];
    dataset[0] = ["cmu", "CMU", "-", "http://domedb.perception.cs.cmu.edu/", "Image", "3-D Estimation", "-", "-", "1", "-"];
    dataset[1] = ["human-3.6m", "Human 3.6M", "The Human3.6M dataset is one of the largest motio…on progressive scan cameras to acquire video ...", "http://vision.imar.ro/human3.6m/description.php", "Image", "3-D Estimation", "3D_Human_Pose_Estimation,3D_Absolute_Human_Pose_Estimation,Human_action_generation", "-", "2", "-"];
    dataset[2] = ["apoloscape", "ApoloScape", "-", "http://apolloscape.auto/", "Image", "Autonomous Driving", "-", "-", "3", "https://capsulesbot.com/blog/2018/08/24/apolloscape-posenet-pytorch.html"];
    dataset[3] = ["cifar-10", "cifar-10", "The CIFAR-10 dataset (Canadian Institute for Adva…usive classes: airplane, automobile (but not ...", "https://www.cs.toronto.edu/~kriz/cifar.html", "Image", "Classification", "Image_Classification,Image_Generation,Graph_Classification", "60000", "4", "https://ermlab.com/en/blog/nlp/cifar-10-classification-using-keras-tutorial/"];
    dataset[4] = ["cifar-100", "cifar-100", "The CIFAR-100 dataset (Canadian Institute for Adv…20 superclasses. There are 600 images per cla...", "https://www.cs.toronto.edu/~kriz/cifar.html", "Image", "Classification", "Image_Classification,Image_Generation,Few-Shot_Image_Classification", "60000", "5", "-"];
    dataset[5] = ["omniglot", "omniglot", "Omniglot is a large dataset of hand-written chara… images and strokes data. Stroke data are coo...", "https://github.com/brendenlake/omniglot#python", "Image", "Classification", "Few-Shot_Image_Classification,Density_Estimation,Multi-Task_Learning", "38300", "6", "https://towardsdatascience.com/few-shot-learning-with-prototypical-networks-87949de03ccd"];
    dataset[6] = ["mnist", "mnist", "The MNIST database (Modified National Institute o…t is a subset of a larger NIST Special Databa...", "http://yann.lecun.com/exdb/mnist/", "Image", "Classification", "Image_Classification,Image_Generation,Domain_Adaptation", "60000", "7", "https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d"];
    dataset[7] = ["celeba", "celebA", "CelebFaces Attributes dataset contains 202,599 fa…cial attributes like hair color, gender and age.", "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html", "Image", "Classification", "Image_Classification,Image_Generation,Face_Alignment", "-", "8", "-"];
    dataset[8] = ["svhn", "SVHN", "The Street View House Number (SVHN) is a digit cl…images are centered in the digit of interest,...", "http://ufldl.stanford.edu/housenumbers/", "Image", "Classification", "Image_Classification,Domain_Adaption,Semi-Supervised_Image_Classification", "-", "9", "-"];
    dataset[9] = ["street_style_dataset_of_matzen", "Street Style dataset of Matzen", "-", "http://streetstyle.cs.cornell.edu/", "Image", "Classification", "-", "-", "10", "-"];
    dataset[10] = ["pku_vehicleid", "PKU VehicleID (VehicleID)", "The “VehicleID” dataset contains CARS captured du…e entire dataset. Each image is attached with...", "https://pkuml.org/resources/pku-vehicleid.html", "Image", "Classification", "Vehicle_Re-Identification", "-", "11", "-"];
    dataset[11] = ["the_in-shop_clothes", "The In-shop Clothes", "-", "http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html", "Image", "Classification", "-", "-", "12", "-"];
    dataset[12] = ["taskonomy", "Taskonomy", "Taskonomy provides a large and high-quality datas…, and MIT Places. &nbsp;Globally consistent c...", "http://taskonomy.stanford.edu/", "Image", "Depth Estimation", "Depth_Estimation,Surface_Normals_Estimation", "-", "13", "-"];
    dataset[13] = ["cuhk_face_sketch_database", "CUHK Face Sketch Database (CUFS)", "-", "http://www.ee.cuhk.edu.hk/~xgwang/datasets.html", "Image", "Face Sketch", "-", "-", "14", "-"];
    dataset[14] = ["chestx-ray8", "ChestX-ray8", "ChestX-ray8 is a medical imaging dataset which co…ined from the text radiological reports via N...", "https://www.kaggle.com/nih-chest-xrays/data", "Image", "Medical Classification", "Image_Classification,Computed_Tomography(CT)", "-", "15", "-"];
    dataset[15] = ["kitti", "kitti", "KITTI (Karlsruhe Institute of Technology and Toyo…orded with a variety of sensor modalities, in...", "http://www.cvlibs.net/datasets/kitti/", "Image", "Object Detection", "Object_Detection,Semantice_Segmentation,Image_Super-Resolution", "&gt;100 GB of data", "16", "https://github.com/joseph-zhang/KITTI-TorchLoader"];
    dataset[16] = ["pascal_voc_2012", "pascal voc 2012", "-", "http://host.robots.ox.ac.uk/pascal/VOC/voc2012/", "Image", "Object Detection", "-", "-", "17", "-"];
    dataset[17] = ["cityscapes", "Cityscapes", "Cityscapes is a large-scale database which focuse…lat surfaces, humans, vehicles, constructions...", "https://www.cityscapes-dataset.com/", "Image", "Object Detection", "Image_Generation,Semantic_Segmentation,Image-to-Image_Translation", "25000", "18", "-"];
    dataset[18] = ["aflw", "AFLW", "The Annotated Facial Landmarks in the Wild (AFLW)…nder) as well as general imaging and environm...", "https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/", "Image", "Object Detection", "Face_Alignment,Facial_Landmark's_Detection,Low-Light_Image_Enhancement", "-", "19", "-"];
    dataset[19] = ["caltech_101", "Caltech 101", "The Caltech101 dataset contains images from 101 o…ries. For each object category, there are abo...", "http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/", "Image", "Object Detection", "Fine-Grained_Image_Classification,Semi-Supervised_Image_Classificatino,Density_Estimation", "9146", "20", "-"];
    dataset[20] = ["caltech_256", "Caltech 256", "Caltech-256 is an object recognition dataset cont…least 80 images. The dataset is a superset of...", "https://authors.library.caltech.edu/7694/", "Image", "Object Detection", "Few-Shot_Image_Classification,Semi-Supervised_Image_Classification", "30607", "21", "-"];
    dataset[21] = ["amazon", "Amazon", "-", "https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/cd-create-dataset.html", "Image", "Object Detection", "-", "-", "22", "-"];
    dataset[22] = ["nlpr", "NLPR", "The NLPR dataset for salient object detection con…., offices, campuses, streets and supermarkets).", "https://www.abbreviationfinder.org/ko/acronyms/nlpr.html", "Image", "Object Detection", "RGB-D_Salient_Object_Detection", "-", "23", "-"];
    dataset[23] = ["coco", "coco", "The MS COCO (Microsoft Common Objects in Context)… version of MS COCO dataset was released in 2...", "https://cocodataset.org/#home", "Image", "Object Recognition", "Pose_Estimation,Object_Detection,Semantic_Segmentation", "2500000", "24", "https://medium.com/fullstackai/how-to-train-an-ob…ith-your-own-coco-dataset-in-pytorch-319e7090da5"];
    dataset[24] = ["imagenet", "imagenet", "The ImageNet dataset contains 14,197,122 annotate…age classification and object detection. The ...", "http://image-net.org/about-overview", "Image", "Object Recognition", "Image_Classification,Image_Generation,Few-Shot_Learning", "14197122", "25", "-"];
    dataset[25] = ["sun", "sun", "-", "https://vision.princeton.edu/projects/2010/SUN/", "Image", "Object Recognition", "-", "131,067", "26", "-"];
    dataset[26] = ["lsun", "lsun", "The Large-scale Scene Understanding (LSUN) challe…such as dining room, bedroom, chicken, outdoo...", "https://www.yf.io/p/lsun", "Image", "Saliency Detection", "Image_Generation", "-", "27", "-"];
    dataset[27] = ["replica", "Replica", "The Replica Dataset is a dataset of high quality …urface information, planar segmentation as we...", "https://github.com/facebookresearch/Replica-Dataset", "Image", "Scene Generation", "Domain_Adaption,Visual_Navigation,Scene_Generation", "-", "28", "-"];
    dataset[28] = ["scannet", "scannet", "ScanNet is an instance-level indoor RGB-D dataset…s collected 1513 annotated scans with an appr...", "http://www.scan-net.org/", "Image", "Semantic Segmentation", "Semantic_Segmentation,Depth_Estimation,3D_Reconstruction", "-", "29", "-"];
    dataset[29] = ["nyu_depth_v1_v2", "nyu depth V1, V2", "-", "https://cs.nyu.edu", "Image", "Semantic Segmentation", "-", "-", "30", "-"];
    dataset[30] = ["lip", "lip", "The LIP (Look into Person) dataset is a large-sca…2D human poses with 16 key points. The images...", "http://sysu-hcp.net/lip/index.php", "Image", "Semantic Segmentation", "Semantic_Segmentation", "-", "31", "-"];
    dataset[31] = ["ade", "ADE", "The ADE20K semantic segmentation dataset contains…clude stuffs like sky, road, grass, and discr...", "https://groups.csail.mit.edu/vision/datasets/ADE20K/index.html", "Image", "Semantic Segmentation", "Semantic_Segmentation,Image-to-Image_Translation,Scene_Understanding", "-", "32", "-"];
    dataset[32] = ["ffhq", "ffhq", "Flickr-Faces-HQ (FFHQ) consists of 70,000 high-qu…ssories such as eyeglasses, sunglasses, hats,...", "https://github.com/NVlabs/ffhq-dataset", "Image", "Super Resolution", "Image_Generation,Image_Super-Resolution,Image_Inpainting", "-", "33", "-"];
    dataset[33] = ["ucf", "ucf", "UCF101 dataset is an extension of UCF50 and consi… Human-object interactions, Playing musical i...", "https://www.crcv.ucf.edu/data/UCF101.php#Results_on_UCF101", "Video", "Action Recognition", "Temporal_Action_Localization,Action_Recognition,Action_Detection", "-", "1", "-"];
    dataset[34] = ["activitynet", "Activitynet", "The ActivityNet dataset contains 200 different ty…ms of both the number of activity categories ...", "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html", "Video", "Action Recognition", "Temporal_Action_Localization,Action_Recognition,Action_Classification", "-", "2", "-"];
    dataset[35] = ["ntu", "ntu", "-", "http://rose1.ntu.edu.sg/datasets/actionrecognition.asp", "Video", "Action Recognition", "-", "-", "3", "-"];
    dataset[36] = ["kinetics", "kinetics", "The Kinetics dataset is a large-scale, high-quali…clips for each action class. Each video clip ...", "https://arxiv.org/abs/1705.06950", "Video", "Action Recognition", "Temporal_Action_Localization,Video_Classification,Action_Recognition", "-", "4", "-"];
    dataset[37] = ["youtube_8m_segments_dataset", "YouTube-8M Segments Dataset", "The YouTube-8M dataset is a large scale video dat…set, and test set. In the training set, each ...", "http://research.google.com/youtube8m/index.html", "Video", "Classification", "Video_Classification,Video_Prediction", "8 million", "5", "-"];
    dataset[38] = ["davis_16", "davis 16", "DAVIS16 is a dataset for video object segmentatio…). Per-frame pixel-wise annotations are offered.", "https://davischallenge.org/index.html", "Video", "Object Segmentation", "Video_Object_Segmentation,Video_Salient_Object_Detection,Unsupervised_Video_Object_Segmentation", "-", "6", "-"];
    dataset[39] = ["davis_17", "davis 17", "DAVIS17 is a dataset for video object segmentatio… for training, 30 for validation, 60 for testing", "https://davischallenge.org/index.html", "Video", "Object Segmentation", "Semantic_Segmentation,Video_Object_Segmentation,Referring_Expression_Segmentation", "-", "7", "-"];
    dataset[40] = ["davis_18", "davis 18", "-", "https://davischallenge.org/index.html", "Video", "Object Segmentation", "-", "-", "8", "-"];
    dataset[41] = ["davis_19", "davis 19", "-", "https://davischallenge.org/index.html", "Video", "Object Segmentation", "-", "-", "9", "-"];
    dataset[42] = ["mot", "MOT", "-", "https://motchallenge.net/", "Video", "Object Tracking", "-", "-", "10", "-"];
    dataset[43] = ["vot", "vot", "-", "https://www.votchallenge.net/index.html", "Video", "Object Tracking", "-", "-", "11", "-"];
    dataset[44] = ["dexter", "dexter", "-", "http://archive.ics.uci.edu/ml//datasets/Dexter", "Text", "Classification", "-", "2600", "1", "-"];
    dataset[45] = ["ubuntu_dialogue", "ubuntu dialogue", "Ubuntu Dialogue Corpus (UDC) is a dataset contain…ilding dialogue managers based on neural lang...", "https://ubuntudialogue.org/", "Text", "Dialogue Generation", "Dialogue_Generation,Conversational_Response_Selection,Answer_Selection", "-", "2", "-"];
    dataset[46] = ["wmt19", "wmt19", "-", "http://www.statmt.org/wmt19/", "Text", "Machine Translation", "-", "-", "3", "-"];
    dataset[47] = ["wmt18", "wmt18", "WMT 2018 is a collection of datasets used in shar…on. &nbsp;&nbsp;&nbsp;The conference featured...", "http://www.statmt.org/wmt18/papers.html", "Text", "Machine Translation", "Machine_Translation", "-", "4", "-"];
    dataset[48] = ["wmt17", "wmt17", "-", "http://www.statmt.org/wmt17/results.html", "Text", "Machine Translation", "-", "-", "5", "-"];
    dataset[49] = ["wmt16", "wmt16", "WMT 2016 is a collection of datasets used in shar…red tasks: &nbsp;&nbsp;&nbsp;a news translati...", "http://www.statmt.org/wmt16/", "Text", "Machine Translation", "Machine_Translation,Unsupervised_Machine_Translation", "-", "6", "-"];
    dataset[50] = ["wmt15", "wmt15", "WMT 2015 is a collection of datasets used in shar…quality estimation task, &nbsp;an automatic p...", "http://www.statmt.org/wmt15/", "Text", "Machine Translation", "Machine_Translation", "-", "7", "-"];
    dataset[51] = ["wmt14", "wmt14", "WMT 2014 is a collection of datasets used in shar…ics task, &nbsp;a medical text translation task.", "http://www.statmt.org/wmt14/", "Text", "Machine Translation", "Machine_Translation,Unsupervised_Machine_Translation", "-", "8", "-"];
    dataset[52] = ["semeval-2016", "SemEval-2016", "-", "https://alt.qcri.org/semeval2016/index.php?id=tasks", "Text", "Word Sentiment", "-", "-", "9", "-"];
    dataset[53] = ["bfm", "BFM", "-", "https://faces.dmi.unibas.ch/bfm/?nav=1-0&amp;id=basel_face_model", "3-D Image", "3-D Estimation", "-", "-", "1", "-"];
    dataset[54] = ["pix3d", "Pix3D", "The Pix3D dataset is a large-scale benchmark of d…struction, retrieval, viewpoint estimation, etc.", "http://pix3d.csail.mit.edu/", "3-D Image", "Classification", "3D_Shape_Reconstruction,3D_Shape_Modeling,3D_Shape_Classification", "-", "2", "-"];
    dataset[55] = ["shrec", "shrec", "The SHREC dataset contains 14 dynamic gestures pe… and 10 times by each participant in two way:...", "http://tosca.cs.technion.ac.il/book/shrec_robustness2010.html", "3-D Image", "Object Recognition", "Gesture_Recognition,Hand_Gesture_Recognition,Skeleton_Based_Action_Recognition", "-", "3", "-"];
    dataset[56] = ["shapenetcore", "shapenetCore", "-", "https://www.shapenet.org/", "3-D Image", "Semantic Segmentation", "-", "-", "4", "-"];
    dataset[57] = ["faust", "faust", "The FAUST dataset is a dataset of real 3D scans o…100 non-watertight meshes with 6,890 nodes each.", "http://faust.is.tue.mpg.de/", "3-D Image", "Semantic Segmentation", "Semantic_Segmentation,3D_Reconstruction,3D_Point_Cloud_Matching", "-", "5", "-"];
    dataset[58] = ["scape", "Scape", "-", "https://ai.stanford.edu/~drago/Projects/scape/scape.html", "3-D Image", "3-D Estimation", "-", "-", "6", "-"];
    dataset[59] = ["voxceleb", "VoxCeleb", "-", "http://www.robots.ox.ac.uk/~vgg/data/voxceleb/", "Sound", "Video Reconstruction", "-", "-", "1", "-"];

    var colosseum = [];
    colosseum[0] = ["천하제일 얼굴 인식대회","2022.04.01","2022.05.01","celebA"];
    colosseum[1] = ["도로위 인식의 최강자 선발 대회","2022.06.01","2022.07.01","kitti"];
    colosseum[2] = ["Did you understand what I said?","2022.08.01","2022.09.01","wmt19"];
    
    //board.sort(date_descending); //날짜 내림차순
    function date_descending(a, b) {
    var dateA = new Date(a[2]).getTime();
    var dateB = new Date(b[2]).getTime();
    return dateA < dateB ? 1 : -1;};
    
    function number_descending(a, b) { // 내림차순  
    var numA = (a[3]);
    var numB = (b[3]);  
    return numB - numA;}

    function dataset_number_descending(a, b) { //dataset 데이터셋 숫자 내림차순  
    var numA = (a[8]);
    var numB = (b[8]);  
    return numB - numA;}

    function save_article(i) {//글 제목을 눌렀을때 이 글의 board 인덱스를 6-1forum-contents에게 넘겨주기 위함
        window.localStorage.setItem("forum_value_1",i);
    }

    function make_list1(){//왼쪽 알림판 리스트 생성
        board.sort(date_descending);
        apply_change();//정렬하고 정렬한 board를 localstorage에 다시 저장해서 최신 상태를 반영함 
        var list1 = document.getElementById("list1");//DOM
        var length = dataset.length;
        var final_code="";
        for (var i = 2; i>=0; i--){
            var code="<li><a href=''>"+dataset[length-1-i][1]+" / "+dataset[length-1-i][4]+"</a></li>";
            final_code=final_code+code;
        }

        var date1 = new Date('2022.06.24');
        for (var i = 0; i<3; i++){
            var date2 = new Date(colosseum[i][1]);
            if(date2 > date1){
                var code="<li><a href=''>"+colosseum[i][0]+" / "+colosseum[i][3]+" / "+colosseum[i][1]+"~"+colosseum[i][2]+"</a></li>";
                final_code=final_code+code;
            }
        }
        list1.innerHTML = final_code;//innerHTML로 div에 HTML코드 삽입
    }
    

    function make_list2(){//오른쪽 알림판 리스트 생성
        board.sort(number_descending);
        apply_change();
        dataset.sort(dataset_number_descending);
        var list2 = document.getElementById("list2");
        var final_code="";
        for (var i = 0; i<3; i++){
            var code="<li onclick='save_article("+i+")'><a href='6-1forum-contents.html'>"+board[i][0]+" / "+board[i][2]+"</a></li>";
            final_code=final_code+code;
        }
        for (var i = 0; i<3; i++){
            var code="<li><a href=''>"+colosseum[i][0]+" / "+colosseum[i][3]+" / "+colosseum[i][1]+"~"+colosseum[i][2]+"</a></li>";
            final_code=final_code+code;
        }
        for (var i = 0; i<3; i++){
            var code="<li><a href=''>"+dataset[i][1]+" / "+dataset[i][4]+"</a></li>";
            final_code=final_code+code;
        }
        list2.innerHTML = final_code;
    }
    

    function apply_change(){//board를 localstorage에 다시 저장해서 최신 상태를 반영함 
        window.localStorage.setItem("board",JSON.stringify(board));//localstorage에 배열을 저장하는 방법
    }

    config();
    var output = localStorage.getItem("board");
    var board = JSON.parse(output);//localstorage에 저장된 배열을 여기서 사용하기 위해 불러옴
    make_list1();
    make_list2();
    </script>

</html>